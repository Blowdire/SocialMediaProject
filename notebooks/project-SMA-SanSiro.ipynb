{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Objective of the Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "Analisi del sentiment relativo al dibattito sulla demolizione dello stadio di San Siro a Milano e individuazione di eventuali 'influencer' sul tema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'4.12.1'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "\n",
    "import re\n",
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from numpy.core.multiarray import result_type\n",
    "import time\n",
    "tweepy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the keys here\n",
    "consumer_key = 'VPzjkqKl2y1uSTJQvnVqS9e1X' \n",
    "consumer_secret = 'STG2IzVMf65vPGeOvBQyzdeoKBExAr5sIkhOaBeDe2fnIN14vY'\n",
    "access_token = '1508409949835214853-HIyZJ3oT32TijKsdNDhGFZEEQTWwau'\n",
    "access_token_secret = 'uLcs9hUYmLdocxkaSfXo69Gii46TISu5qZj5F6f6fBfnW'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets Download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is creating an OAuthHandler instance. We pass our consumer key and access token which we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass the OAuthHandler instance into the API method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets that contain a specific hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [27], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m list_tweets \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tweet \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtweepy\u001B[49m\u001B[38;5;241m.\u001B[39mCursor(api\u001B[38;5;241m.\u001B[39msearch_tweets, q\u001B[38;5;241m=\u001B[39mhashtag, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mit\u001B[39m\u001B[38;5;124m'\u001B[39m, until \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2022-11-24\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mitems(\u001B[38;5;241m100\u001B[39m):\n\u001B[0;32m     10\u001B[0m       \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentering\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     11\u001B[0m       full_text \u001B[38;5;241m=\u001B[39m api\u001B[38;5;241m.\u001B[39mget_status(tweet\u001B[38;5;241m.\u001B[39mid, tweet_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mextended\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39m_json[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_text\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "Cell \u001B[1;32mIn [27], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m list_tweets \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tweet \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtweepy\u001B[49m\u001B[38;5;241m.\u001B[39mCursor(api\u001B[38;5;241m.\u001B[39msearch_tweets, q\u001B[38;5;241m=\u001B[39mhashtag, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mit\u001B[39m\u001B[38;5;124m'\u001B[39m, until \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2022-11-24\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mitems(\u001B[38;5;241m100\u001B[39m):\n\u001B[0;32m     10\u001B[0m       \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentering\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     11\u001B[0m       full_text \u001B[38;5;241m=\u001B[39m api\u001B[38;5;241m.\u001B[39mget_status(tweet\u001B[38;5;241m.\u001B[39mid, tweet_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mextended\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39m_json[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_text\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import time\n",
    "hashtag = \"#SanSiro\"\n",
    "\n",
    "list_tweets = []\n",
    "\n",
    "for i in range(10):\n",
    "    for tweet in tweepy.Cursor(api.search_tweets, q=hashtag, count=100, lang='it', until = '2022-11-24').items(100):\n",
    "      print('entering')\n",
    "      full_text = api.get_status(tweet.id, tweet_mode='extended')._json['full_text']\n",
    "      print(tweet.id)\n",
    "      list_tweets.append([tweet.created_at, tweet.id, full_text, tweet.favorite_count, tweet.retweet_count, tweet.user.screen_name,\n",
    "      tweet.user.location, tweet.retweeted, tweet.entities['user_mentions'], tweet.entities['hashtags']])\n",
    "    for j in range(60):\n",
    "        time.sleep(1)\n",
    "\n",
    "# items is the maximum number of tweets to download.\n",
    "# count is the number of tweets to return per page, up to a maximum of 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                       date                   id  \\\n0 2022-12-29 08:03:16+00:00  1608373070388928513   \n1 2022-12-29 08:02:38+00:00  1608372908187090944   \n2 2022-12-28 18:54:10+00:00  1608174483835334656   \n3 2022-12-28 17:17:25+00:00  1608150136924037120   \n4 2022-12-28 16:45:15+00:00  1608142041497624576   \n\n                                                text  like  n_rt  \\\n0  Bello Erling con la maglia rossonera ðŸ¥º\\n-\\n-\\n...     1     0   \n1  ðŸ‡µðŸ‡¹ðŸ“ž Secondo la Gazzetta dello Sport, Leao star...     1     0   \n2  @FrauPretzel A #Sala frega solo la sua tasca ,...     2     0   \n3  Comunque, vorrei far notare che la parte stori...     0     0   \n4  Un bel fuori gioco di qualche anno fa contro d...     1     0   \n\n         author location  retweeted  \\\n0   icrossonero               False   \n1   icrossonero               False   \n2      castel62  Milano       False   \n3  loperatoreOC               False   \n4     labatwitt    Monza      False   \n\n                                       user_mentions  \\\n0                                                 []   \n1                                                 []   \n2  [{'screen_name': 'FrauPretzel', 'name': 'La Fr...   \n3                                                 []   \n4                                                 []   \n\n                                             hastags  \n0  [{'text': 'acmilan', 'indices': [45, 53]}, {'t...  \n1                                                 []  \n2            [{'text': 'Sala', 'indices': [15, 20]}]  \n3         [{'text': 'SanSiro', 'indices': [72, 80]}]  \n4  [{'text': 'SanSiro', 'indices': [68, 76]}, {'t...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id</th>\n      <th>text</th>\n      <th>like</th>\n      <th>n_rt</th>\n      <th>author</th>\n      <th>location</th>\n      <th>retweeted</th>\n      <th>user_mentions</th>\n      <th>hastags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-12-29 08:03:16+00:00</td>\n      <td>1608373070388928513</td>\n      <td>Bello Erling con la maglia rossonera ðŸ¥º\\n-\\n-\\n...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>icrossonero</td>\n      <td></td>\n      <td>False</td>\n      <td>[]</td>\n      <td>[{'text': 'acmilan', 'indices': [45, 53]}, {'t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-12-29 08:02:38+00:00</td>\n      <td>1608372908187090944</td>\n      <td>ðŸ‡µðŸ‡¹ðŸ“ž Secondo la Gazzetta dello Sport, Leao star...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>icrossonero</td>\n      <td></td>\n      <td>False</td>\n      <td>[]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-12-28 18:54:10+00:00</td>\n      <td>1608174483835334656</td>\n      <td>@FrauPretzel A #Sala frega solo la sua tasca ,...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>castel62</td>\n      <td>Milano</td>\n      <td>False</td>\n      <td>[{'screen_name': 'FrauPretzel', 'name': 'La Fr...</td>\n      <td>[{'text': 'Sala', 'indices': [15, 20]}]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-12-28 17:17:25+00:00</td>\n      <td>1608150136924037120</td>\n      <td>Comunque, vorrei far notare che la parte stori...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>loperatoreOC</td>\n      <td></td>\n      <td>False</td>\n      <td>[]</td>\n      <td>[{'text': 'SanSiro', 'indices': [72, 80]}]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-12-28 16:45:15+00:00</td>\n      <td>1608142041497624576</td>\n      <td>Un bel fuori gioco di qualche anno fa contro d...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>labatwitt</td>\n      <td>Monza</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>[{'text': 'SanSiro', 'indices': [68, 76]}, {'t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.DataFrame(list_tweets, columns=['date','id','text','like','n_rt','author','location','retweeted', 'user_mentions', 'hastags'])\n",
    "tweets.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_tweets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn list_tweet into a DataFrame changing column names\n",
    "tweets = pd.DataFrame(list_tweets, columns=['date','id','text','like','n_rt','author','location','retweeted', 'user_mentions', 'hastags'])\n",
    "tweets.to_csv('../data/SanSiro.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                       date                   id  \\\n0           0  2022-12-26 21:10:23+00:00  1607483990822510592   \n1           1  2022-12-26 19:52:30+00:00  1607464388960874496   \n2           2  2022-12-26 19:10:23+00:00  1607453790814208001   \n3           3  2022-12-26 18:14:15+00:00  1607439663090012160   \n4           4  2022-12-26 16:24:07+00:00  1607411947355635717   \n\n                                                text  like  n_rt  \\\n0  #ZlatanIbrahimovic: \"Giocare a #SanSiro mi fa ...     0     0   \n1  Ragazzi cerco una informazione su #Sansiro . D...     0     0   \n2  #SanSiro in bilico, un monumento celebrato in ...    13     0   \n3  RT @MilanTV: Incredibile finale a #SanSiro, #M...     0     9   \n4  RT @CalcioFinanza: #SanSiro, il Comune approva...     0     4   \n\n          author        location  retweeted  \\\n0    MilanHC2022             NaN      False   \n1      TizRoss83           mondo      False   \n2       cmdotcom  milano, italia      False   \n3  Profilo3Marco             NaN      False   \n4   Giorgiogigox         veneto       False   \n\n                                       user_mentions  \\\n0                                                 []   \n1                                                 []   \n2                                                 []   \n3  [{'screen_name': 'MilanTV', 'name': 'Milan TV'...   \n4  [{'screen_name': 'CalcioFinanza', 'name': 'Cal...   \n\n                                             hastags  \n0  [{'text': 'ZlatanIbrahimovic', 'indices': [0, ...  \n1         [{'text': 'Sansiro', 'indices': [34, 42]}]  \n2  [{'text': 'SanSiro', 'indices': [0, 8]}, {'tex...  \n3  [{'text': 'SanSiro', 'indices': [34, 42]}, {'t...  \n4  [{'text': 'SanSiro', 'indices': [19, 27]}, {'t...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date</th>\n      <th>id</th>\n      <th>text</th>\n      <th>like</th>\n      <th>n_rt</th>\n      <th>author</th>\n      <th>location</th>\n      <th>retweeted</th>\n      <th>user_mentions</th>\n      <th>hastags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2022-12-26 21:10:23+00:00</td>\n      <td>1607483990822510592</td>\n      <td>#ZlatanIbrahimovic: \"Giocare a #SanSiro mi fa ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>MilanHC2022</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>[{'text': 'ZlatanIbrahimovic', 'indices': [0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2022-12-26 19:52:30+00:00</td>\n      <td>1607464388960874496</td>\n      <td>Ragazzi cerco una informazione su #Sansiro . D...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>TizRoss83</td>\n      <td>mondo</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>[{'text': 'Sansiro', 'indices': [34, 42]}]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2022-12-26 19:10:23+00:00</td>\n      <td>1607453790814208001</td>\n      <td>#SanSiro in bilico, un monumento celebrato in ...</td>\n      <td>13</td>\n      <td>0</td>\n      <td>cmdotcom</td>\n      <td>milano, italia</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>[{'text': 'SanSiro', 'indices': [0, 8]}, {'tex...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2022-12-26 18:14:15+00:00</td>\n      <td>1607439663090012160</td>\n      <td>RT @MilanTV: Incredibile finale a #SanSiro, #M...</td>\n      <td>0</td>\n      <td>9</td>\n      <td>Profilo3Marco</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[{'screen_name': 'MilanTV', 'name': 'Milan TV'...</td>\n      <td>[{'text': 'SanSiro', 'indices': [34, 42]}, {'t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2022-12-26 16:24:07+00:00</td>\n      <td>1607411947355635717</td>\n      <td>RT @CalcioFinanza: #SanSiro, il Comune approva...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>Giorgiogigox</td>\n      <td>veneto</td>\n      <td>False</td>\n      <td>[{'screen_name': 'CalcioFinanza', 'name': 'Cal...</td>\n      <td>[{'text': 'SanSiro', 'indices': [19, 27]}, {'t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_loaded = pd.read_csv('../data/SanSiro.csv')\n",
    "#tweets_loaded = tweets.drop('Unnamed: 0', axis=1)\n",
    "tweets_loaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'id', 'text', 'like', 'n_rt', 'author', 'location', 'retweeted',\n",
       "       'user_mentions', 'hastags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "tweets.drop_duplicates(subset =\"id\", inplace = True)\n",
    "tweets.reset_index(drop = True, inplace = True)\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mc:\\Users\\FC\\Desktop\\uniProjects\\SocialMediaProject\\notebooks\\project-SMA-SanSiro.ipynb Cell 19\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FC/Desktop/uniProjects/SocialMediaProject/notebooks/project-SMA-SanSiro.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m \u001B[39m# Change date format\u001B[39;00m\n\u001B[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/FC/Desktop/uniProjects/SocialMediaProject/notebooks/project-SMA-SanSiro.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001B[0m day \u001B[39m=\u001B[39m tweets[\u001B[39m'\u001B[39;49m\u001B[39mdate\u001B[39;49m\u001B[39m'\u001B[39;49m]\u001B[39m.\u001B[39;49mdt\u001B[39m.\u001B[39mday\n\u001B[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FC/Desktop/uniProjects/SocialMediaProject/notebooks/project-SMA-SanSiro.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001B[0m month \u001B[39m=\u001B[39m tweets[\u001B[39m'\u001B[39m\u001B[39mdate\u001B[39m\u001B[39m'\u001B[39m]\u001B[39m.\u001B[39mdt\u001B[39m.\u001B[39mmonth\n\u001B[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FC/Desktop/uniProjects/SocialMediaProject/notebooks/project-SMA-SanSiro.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001B[0m year \u001B[39m=\u001B[39m tweets[\u001B[39m'\u001B[39m\u001B[39mdate\u001B[39m\u001B[39m'\u001B[39m]\u001B[39m.\u001B[39mdt\u001B[39m.\u001B[39myear\n",
      "File \u001B[1;32mc:\\Users\\FC\\miniconda3\\envs\\twitter\\lib\\site-packages\\pandas\\core\\generic.py:5583\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5576\u001B[0m \u001B[39mif\u001B[39;00m (\n\u001B[0;32m   5577\u001B[0m     name \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_internal_names_set\n\u001B[0;32m   5578\u001B[0m     \u001B[39mand\u001B[39;00m name \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_metadata\n\u001B[0;32m   5579\u001B[0m     \u001B[39mand\u001B[39;00m name \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_accessors\n\u001B[0;32m   5580\u001B[0m     \u001B[39mand\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_info_axis\u001B[39m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5581\u001B[0m ):\n\u001B[0;32m   5582\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m[name]\n\u001B[1;32m-> 5583\u001B[0m \u001B[39mreturn\u001B[39;00m \u001B[39mobject\u001B[39;49m\u001B[39m.\u001B[39;49m\u001B[39m__getattribute__\u001B[39;49m(\u001B[39mself\u001B[39;49m, name)\n",
      "File \u001B[1;32mc:\\Users\\FC\\miniconda3\\envs\\twitter\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001B[0m, in \u001B[0;36mCachedAccessor.__get__\u001B[1;34m(self, obj, cls)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[39mif\u001B[39;00m obj \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m    180\u001B[0m     \u001B[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001B[39;00m\n\u001B[0;32m    181\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_accessor\n\u001B[1;32m--> 182\u001B[0m accessor_obj \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_accessor(obj)\n\u001B[0;32m    183\u001B[0m \u001B[39m# Replace the property with the accessor object. Inspired by:\u001B[39;00m\n\u001B[0;32m    184\u001B[0m \u001B[39m# https://www.pydanny.com/cached-property.html\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001B[39;00m\n\u001B[0;32m    186\u001B[0m \u001B[39m# NDFrame\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[39mobject\u001B[39m\u001B[39m.\u001B[39m\u001B[39m__setattr__\u001B[39m(obj, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_name, accessor_obj)\n",
      "File \u001B[1;32mc:\\Users\\FC\\miniconda3\\envs\\twitter\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:509\u001B[0m, in \u001B[0;36mCombinedDatetimelikeProperties.__new__\u001B[1;34m(cls, data)\u001B[0m\n\u001B[0;32m    506\u001B[0m \u001B[39melif\u001B[39;00m is_period_dtype(data\u001B[39m.\u001B[39mdtype):\n\u001B[0;32m    507\u001B[0m     \u001B[39mreturn\u001B[39;00m PeriodProperties(data, orig)\n\u001B[1;32m--> 509\u001B[0m \u001B[39mraise\u001B[39;00m \u001B[39mAttributeError\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39mCan only use .dt accessor with datetimelike values\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Change date format\n",
    "day = tweets['date'].dt.day\n",
    "month = tweets['date'].dt.month\n",
    "year = tweets['date'].dt.year\n",
    "\n",
    "date = year.astype(str) + month.astype(str).str.zfill(2) + day.astype(str).str.zfill(2)\n",
    "date = pd.to_datetime(date, format='%Y%m%d')\n",
    "tweets.drop(columns = ['date'], inplace = True)\n",
    "tweets['date'] = date\n",
    "\n",
    "# Reorder columns\n",
    "cols = tweets.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "tweets = tweets[cols].copy()\n",
    "\n",
    "print('Tweet per day:')\n",
    "print()\n",
    "print(tweets.groupby('date').count()['id'])\n",
    "# print()\n",
    "# print()\n",
    "# print('Minimum Tweet ID per day:')\n",
    "# print()\n",
    "# print(df_SanSiro.groupby('date').min('id')['id'])\n",
    "# print()\n",
    "# print()\n",
    "# print('Maximum Tweet ID per day:')\n",
    "# print()\n",
    "# print(df_SanSiro.groupby('date').max('id')['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PianetaMilan     10\n",
       "cmdotcom          5\n",
       "sportface2016     4\n",
       "MiTomorrow        4\n",
       "Pradivio          4\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the authors of the tweets and their respective frequency\n",
    "freq_authors = tweets['author'].value_counts()\n",
    "freq_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all hashtags from the full text\n",
    "tweets['hashtags_list'] = tweets['text'].apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
    "\n",
    "# Extract all mentions from the full text\n",
    "tweets['mentions'] = tweets['text'].apply(lambda x: re.findall(r\"@(\\w+)\", x))\n",
    "\n",
    "# \\w matches any single letter, number or underscore (same as [a zA Z0 9_])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK - Natural Language ToolKit is a platform for building Python programs to work with human language data. It provides easy to use interfaces to over 50 corpora and lexical resources, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\FC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\FC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\FC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\FC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # remove numbers and turning words into lower case\n",
    "    data = data.astype(str).str.replace('\\d+','')\n",
    "    lower_text = data.str.lower()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    w_tokenizer = TweetTokenizer()\n",
    "    \n",
    "    # token lemmatization (ex. goes --> go)\n",
    "    def lemmatize_text(text):\n",
    "        return[(lemmatizer.lemmatize(w)) for w in w_tokenizer.tokenize((text))]\n",
    "    \n",
    "    # remove punctuation\n",
    "    def remove_punctuation(words):\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = re.sub(r'[\\w\\s]', '', (word))\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    words = lower_text.apply(lemmatize_text)\n",
    "    words = words.apply(remove_punctuation)\n",
    "    return pd.DataFrame(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FC\\AppData\\Local\\Temp\\ipykernel_14404\\3179111472.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data = data.astype(str).str.replace('\\d+','')\n"
     ]
    }
   ],
   "source": [
    "# apply preprocess_data function\n",
    "pre_tweets = preprocess_data(tweets['text'])\n",
    "tweets['text_proc'] = pre_tweets\n",
    "\n",
    "# delete italian stopwords\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "tweets['text_proc'] = tweets['text_proc'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Social Content Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Sentiment Analysis_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with social media text, we usually want to identify urls, hashtags, smileys as separate objects and do not tokenize it to individual characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Emotion Analysis_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Social Network Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of Centrality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63c35ebd809991b35c43443518cb3da8a509d9076f9b0b6af1c8f1f814340e17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
